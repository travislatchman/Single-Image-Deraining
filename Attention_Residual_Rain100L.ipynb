{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/travislatchman/Single-Image-Deraining/blob/main/Attention_Residual_Rain100L.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "as4OQJiJDDma"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import random\n",
        "import numpy as np\n",
        "import time\n",
        "from PIL import Image\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision import transforms\n",
        "from torchvision.transforms import Lambda\n",
        "from torch.cuda.amp import GradScaler, autocast\n",
        "from torchviz import make_dot\n",
        "\n",
        "from skimage.metrics import peak_signal_noise_ratio as psnr\n",
        "from skimage.metrics import structural_similarity as ssim\n",
        "\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qBVfApbbnozj",
        "outputId": "ba8039c1-9602-4beb-92c1-07c58063ec61"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "11.7\n",
            "GPU Available:  True\n",
            "GPU is available.\n"
          ]
        }
      ],
      "source": [
        "print(torch.version.cuda)\n",
        "\n",
        "print(\"GPU Available: \", torch.cuda.is_available())\n",
        "\n",
        "if torch.cuda.is_available():\n",
        "    print(\"GPU is available.\")\n",
        "else:\n",
        "    print(\"GPU is not available.\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7oaGHlkgDDmf"
      },
      "outputs": [],
      "source": [
        "torch.cuda.empty_cache()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xsSo6K9QDDmg"
      },
      "source": [
        "##### Construct Rain100L Dataset - Load both Rainy and Norainy images"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YdillUkNDDmi"
      },
      "outputs": [],
      "source": [
        "class Rain100L_Dataset(Dataset):\n",
        "    \"\"\"A custom dataset class for the Rain100L dataset.\n",
        "\n",
        "    This class inherits from the PyTorch Dataset class and\n",
        "    is used to load and transform rainy and non-rainy images\n",
        "    from the Rain100L dataset.\n",
        "\n",
        "    Attributes:\n",
        "        rainy_path (str): The path to the directory containing the rainy images.\n",
        "        norainy_path (str): The path to the directory containing the non-rainy images.\n",
        "        data (list): A list of tuples containing the filenames of the rainy and non-rainy images.\n",
        "        transform (callable, optional): An optional transform to apply to both rainy and non-rainy images.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, rainy_path, norainy_path, data, transform=None):\n",
        "        \"\"\"Initialize the Rain100L_Dataset.\n",
        "\n",
        "        Args:\n",
        "            rainy_path (str): The path to the directory containing the rainy images.\n",
        "            norainy_path (str): The path to the directory containing the non-rainy images.\n",
        "            data (list): A list of tuples containing the filenames of the rainy and non-rainy images.\n",
        "            transform (callable, optional): An optional transform to apply to both rainy and non-rainy images.\n",
        "        \"\"\"\n",
        "        self.rainy_path = rainy_path\n",
        "        self.norainy_path = norainy_path\n",
        "        self.data = data\n",
        "        self.transform = transform\n",
        "        \n",
        "    def __len__(self):\n",
        "        \"\"\"Return the number of samples in the dataset.\n",
        "\n",
        "        Returns:\n",
        "            int: The number of samples in the dataset.\n",
        "        \"\"\"\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        \"\"\"Get the rainy and non-rainy images at the given index.\n",
        "\n",
        "        Args:\n",
        "            idx (int): The index of the sample to get.\n",
        "\n",
        "        Returns:\n",
        "            tuple: A tuple containing the rainy and non-rainy images (PIL.Image.Image) at the given index.\n",
        "        \"\"\"\n",
        "        rainy_img_name, norainy_img_name = self.data[idx]\n",
        "        rainy_image = Image.open(os.path.join(self.rainy_path, rainy_img_name))\n",
        "        norainy_image = Image.open(os.path.join(self.norainy_path, norainy_img_name))\n",
        "\n",
        "        if self.transform:\n",
        "            rainy_image = self.transform(rainy_image)\n",
        "            norainy_image = self.transform(norainy_image)\n",
        "\n",
        "        return rainy_image, norainy_image\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MCX-zeuwDDmj"
      },
      "source": [
        "##### First implementation idea for splitting"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VYNrTfvhDDmk"
      },
      "outputs": [],
      "source": [
        "def split_data(rainy_path, norainy_path, train_ratio=0.7, val_ratio=0.2, test_ratio=0.1):\n",
        "    \"\"\"Split the rainy and non-rainy image files into train, validation, and test sets.\n",
        "\n",
        "    The function takes the paths to the directories containing rainy and non-rainy images,\n",
        "    and returns three lists of tuples (rainy_image, non_rainy_image) for train, validation, and test sets.\n",
        "\n",
        "    Args:\n",
        "        rainy_path (str): The path to the directory containing the rainy images.\n",
        "        norainy_path (str): The path to the directory containing the non-rainy images.\n",
        "        train_ratio (float, optional): The ratio of samples to use for the training set. Default is 0.7.\n",
        "        val_ratio (float, optional): The ratio of samples to use for the validation set. Default is 0.2.\n",
        "        test_ratio (float, optional): The ratio of samples to use for the test set. Default is 0.1.\n",
        "\n",
        "    Returns:\n",
        "        tuple: A tuple containing three lists of tuples (rainy_image, non_rainy_image) for train, validation, and test sets.\n",
        "    \"\"\"\n",
        "    # Set a random seed\n",
        "    random.seed(42)\n",
        "\n",
        "    rainy_files = sorted(os.listdir(rainy_path))\n",
        "    norainy_files = sorted(os.listdir(norainy_path))\n",
        "    \n",
        "    data_size = len(rainy_files)\n",
        "    indices = list(range(data_size))\n",
        "    random.shuffle(indices)\n",
        "\n",
        "    train_indices = indices[:int(data_size * train_ratio)]\n",
        "    val_indices = indices[int(data_size * train_ratio):int(data_size * (train_ratio + val_ratio))]\n",
        "    test_indices = indices[int(data_size * (train_ratio + val_ratio)):]\n",
        "\n",
        "    train_data = [(rainy_files[i], norainy_files[i]) for i in train_indices]\n",
        "    val_data = [(rainy_files[i], norainy_files[i]) for i in val_indices]\n",
        "    test_data = [(rainy_files[i], norainy_files[i]) for i in test_indices]\n",
        "\n",
        "    return train_data, val_data, test_data\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rjk2wRAODDmk"
      },
      "source": [
        "### Split the data and create data loaders"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zgmdxu4lDDml"
      },
      "outputs": [],
      "source": [
        "def resize_and_pad(target_width, target_height):\n",
        "    \"\"\"Create a function that resizes and pads an image to the specified dimensions.\n",
        "\n",
        "    This function generates a new function that takes an image as input and returns a\n",
        "    new image with the specified target width and height, preserving its aspect ratio,\n",
        "    and padding the shorter sides with black pixels if needed.\n",
        "\n",
        "    Args:\n",
        "        target_width (int): The target width of the output image.\n",
        "        target_height (int): The target height of the output image.\n",
        "\n",
        "    Returns:\n",
        "        function: A function that takes an image as input and returns a new image\n",
        "                  with the specified target width and height.\n",
        "    \"\"\"\n",
        "    def _resize_and_pad(image):\n",
        "        aspect_ratio = image.width / image.height\n",
        "        if aspect_ratio > 1:  # width > height\n",
        "            new_width = target_width\n",
        "            new_height = int(new_width / aspect_ratio)\n",
        "        else:  # height >= width\n",
        "            new_height = target_height\n",
        "            new_width = int(new_height * aspect_ratio)\n",
        "\n",
        "        resized_image = image.resize((new_width, new_height), Image.BICUBIC)\n",
        "\n",
        "        padded_image = Image.new('RGB', (target_width, target_height), color=0)\n",
        "        left_padding = (target_width - new_width) // 2\n",
        "        top_padding = (target_height - new_height) // 2\n",
        "        padded_image.paste(resized_image, (left_padding, top_padding))\n",
        "        return padded_image\n",
        "\n",
        "    return _resize_and_pad\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TdqQEKRmDDml"
      },
      "outputs": [],
      "source": [
        "rainy_path = r\"G:\\\\My Drive\\Deraining\\\\Rain100L\\\\rainy\"\n",
        "norainy_path = r\"G:\\\\My Drive\\\\Deraining\\\\Rain100L\"\n",
        "\n",
        "\n",
        "train_data, val_data, test_data = split_data(rainy_path, norainy_path)\n",
        "\n",
        "target_width = 480\n",
        "target_height = 320\n",
        "transform = transforms.Compose([\n",
        "    Lambda(resize_and_pad(target_width, target_height)),\n",
        "    transforms.ToTensor()\n",
        "])\n",
        "\n",
        "train_set = Rain100L_Dataset(rainy_path, norainy_path, train_data, transform)\n",
        "val_set = Rain100L_Dataset(rainy_path, norainy_path, val_data, transform)\n",
        "test_set = Rain100L_Dataset(rainy_path, norainy_path, test_data, transform)\n",
        "\n",
        "train_loader = DataLoader(train_set, batch_size=4, shuffle=True)\n",
        "val_loader = DataLoader(val_set, batch_size=4, shuffle=False)\n",
        "test_loader = DataLoader(test_set, batch_size=4, shuffle=False)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GH67Tcu4DDmm"
      },
      "source": [
        "### U-Net with Local Attention and Residual Blocks\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qKEPdJ_qDDmm"
      },
      "outputs": [],
      "source": [
        "class ResidualBlock(nn.Module):\n",
        "    \"\"\"A residual block using two convolutional layers with ReLU activations.\n",
        "\n",
        "    Args:\n",
        "        in_channels (int): Number of input channels.\n",
        "        out_channels (int): Number of output channels.\n",
        "\n",
        "    Attributes:\n",
        "        conv1 (nn.Conv2d): First convolutional layer.\n",
        "        relu1 (nn.ReLU): ReLU activation after the first convolutional layer.\n",
        "        conv2 (nn.Conv2d): Second convolutional layer.\n",
        "        relu2 (nn.ReLU): ReLU activation after the second convolutional layer.\n",
        "        conv_skip (nn.Conv2d, optional): Convolutional layer used when the number of input channels\n",
        "                                         is not equal to the number of output channels.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, in_channels, out_channels):\n",
        "        super(ResidualBlock, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1)\n",
        "        self.relu1 = nn.ReLU(inplace=True)\n",
        "        self.conv2 = nn.Conv2d(out_channels, out_channels, kernel_size=3, padding=1)\n",
        "        self.relu2 = nn.ReLU(inplace=True)\n",
        "\n",
        "        if in_channels != out_channels:\n",
        "            self.conv_skip = nn.Conv2d(in_channels, out_channels, kernel_size=1, padding=0)\n",
        "        else:\n",
        "            self.conv_skip = None\n",
        "\n",
        "    def forward(self, x):\n",
        "        identity = x\n",
        "        out = self.relu1(self.conv1(x))\n",
        "        out = self.conv2(out)\n",
        "\n",
        "        if self.conv_skip is not None:\n",
        "            identity = self.conv_skip(identity)\n",
        "\n",
        "        out += identity\n",
        "        out = self.relu2(out)\n",
        "        return out\n",
        "\n",
        "class LocalAttention(nn.Module):\n",
        "   \"\"\"A local attention layer using a softmax activation.\n",
        "\n",
        "    Args:\n",
        "        channels (int): Number of input and output channels.\n",
        "        k_size (int, optional): Kernel size for the convolutional layer. Default is 3.\n",
        "\n",
        "    Attributes:\n",
        "        conv_W (nn.Conv2d): Convolutional layer used to produce query and key tensors.\n",
        "        softmax (nn.Softmax): Softmax activation for attention weights.\n",
        "        channels (int): Number of input and output channels.\n",
        "    \"\"\"\n",
        "    def __init__(self, channels, k_size=3):\n",
        "        super(LocalAttention, self).__init__()\n",
        "        self.conv_W = nn.Conv2d(channels, channels, kernel_size=k_size, padding=(k_size - 1) // 2)\n",
        "        self.softmax = nn.Softmax(dim=-1)\n",
        "        self.channels = channels\n",
        "\n",
        "    def forward(self, x):\n",
        "        B, C, H, W = x.size()\n",
        "\n",
        "        query = self.conv_W(x).view(B, self.channels, -1)\n",
        "        key = self.conv_W(x).view(B, self.channels, -1)\n",
        "        value = x.view(B, self.channels, -1)\n",
        "\n",
        "        attention_weights = torch.bmm(query.permute(0, 2, 1), key)\n",
        "        attention_weights = self.softmax(attention_weights)\n",
        "\n",
        "        out = torch.bmm(value, attention_weights)\n",
        "        out = out.view(B, self.channels, H, W)\n",
        "\n",
        "        return out\n",
        "\n",
        "class UNet(nn.Module):\n",
        "    \"\"\"U-Net architecture using residual blocks and a local attention layer.\n",
        "\n",
        "    Args:\n",
        "        in_channels (int): Number of input channels.\n",
        "        out_channels (int): Number of output channels.\n",
        "\n",
        "    Attributes:\n",
        "        enc1, enc2, enc3, enc4 (ResidualBlock): Encoder residual blocks.\n",
        "        pool (nn.MaxPool2d): Max pooling layer.\n",
        "        middle (ResidualBlock): Middle residual block.\n",
        "        up4, up3, up2, up1 (nn.Sequential): Up-sampling layers.\n",
        "        dec4, dec3, dec2, dec1 (ResidualBlock): Decoder residual blocks.\n",
        "        local_attention (LocalAttention): Local attention layer.\n",
        "        output (nn.Conv2d): Output convolutional layer.\n",
        "    \"\"\"\n",
        "    def __init__(self, in_channels, out_channels):\n",
        "        super(UNet, self).__init__()\n",
        "\n",
        "        def conv_block(in_channels, out_channels):\n",
        "            return ResidualBlock(in_channels, out_channels)\n",
        "\n",
        "        def up_block(in_channels, out_channels):\n",
        "            return nn.Sequential(\n",
        "                nn.ConvTranspose2d(in_channels, out_channels, kernel_size=2, stride=2),\n",
        "                nn.ReLU(inplace=True)\n",
        "            )\n",
        "\n",
        "        # Reduced channel sizes\n",
        "        self.enc1 = conv_block(in_channels, 32)\n",
        "        self.enc2 = conv_block(32, 64)\n",
        "        self.enc3 = conv_block(64, 128)\n",
        "        self.enc4 = conv_block(128, 256)\n",
        "\n",
        "        self.pool = nn.MaxPool2d(2)\n",
        "\n",
        "        self.middle = conv_block(256, 512)\n",
        "\n",
        "        self.up4 = up_block(512, 256)\n",
        "        self.dec4 = conv_block(512, 256)\n",
        "        self.up3 = up_block(256, 128)\n",
        "        self.dec3 = conv_block(256, 128)\n",
        "        self.local_attention = LocalAttention(128)\n",
        "        self.up2 = up_block(128, 64)\n",
        "        self.dec2 = conv_block(128, 64)\n",
        "\n",
        "        self.up1 = nn.ConvTranspose2d(64, 32, kernel_size=2, stride=2)\n",
        "        self.dec1 = conv_block(64, 32)\n",
        "\n",
        "        self.output = nn.Conv2d(32, out_channels, kernel_size=1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        enc1 = self.enc1(x)\n",
        "        enc2 = self.enc2(self.pool(enc1))\n",
        "        enc3 = self.enc3(self.pool(enc2))\n",
        "        enc4 = self.enc4(self.pool(enc3))\n",
        "\n",
        "        middle = self.middle(self.pool(enc4))\n",
        "\n",
        "        up4 = self.up4(middle)\n",
        "        merge4 = torch.cat([enc4, up4], dim=1)\n",
        "        dec4 = self.dec4(merge4)\n",
        "\n",
        "        up3 = self.up3(dec4)\n",
        "        merge3 = torch.cat([enc3, up3], dim=1)\n",
        "        dec3 = self.dec3(merge3)\n",
        "        dec3 = self.local_attention(dec3)\n",
        "\n",
        "        up2 = self.up2(dec3)\n",
        "        merge2 = torch.cat([enc2, up2], dim=1)\n",
        "        dec2 = self.dec2(merge2)\n",
        "\n",
        "        up1 = self.up1(dec2)\n",
        "        merge1 = torch.cat([enc1, up1], dim=1)\n",
        "        dec1 = self.dec1(merge1)\n",
        "\n",
        "        output = self.output(dec1)\n",
        "        return output\n",
        "\n",
        "unet = UNet(3, 3)  # Adjust input and output channels to 3 for RGB images"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "79LiXfEJDDmn",
        "outputId": "334f68e1-ce2f-4135-f8fb-7a02536c9eaf"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'unet_attention_residual.png'"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Create a dummy input tensor with the same shape as your input data\n",
        "dummy_input = torch.randn(1, 3, 480, 320)  # Adjust the shape as needed\n",
        "\n",
        "# Move the model and dummy input to the device (either GPU or CPU)\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "unet = UNet(3, 3).to(device)\n",
        "dummy_input = dummy_input.to(device)\n",
        "\n",
        "# Run the model with the dummy input and visualize the model architecture\n",
        "output = unet(dummy_input)\n",
        "dot = make_dot(output, params=dict(unet.named_parameters()))\n",
        "dot.format = 'png'\n",
        "dot.render('unet_attention_residual')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pVpFVQrdDDmn"
      },
      "source": [
        "### Visualization in Netron"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yAzThDdwDDmo",
        "outputId": "7654b3d8-4a58-45aa-ce0d-feb2049bdb23"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "================ Diagnostic Run torch.onnx.export version 2.0.0 ================\n",
            "verbose: False, log level: Level.ERROR\n",
            "======================= 0 NONE 0 NOTE 0 WARNING 0 ERROR ========================\n",
            "\n"
          ]
        }
      ],
      "source": [
        "import torch.onnx\n",
        "\n",
        "dummy_input = torch.randn(1, 3, 480, 320)\n",
        "dummy_input = dummy_input.to(device)\n",
        "\n",
        "torch.onnx.export(unet, dummy_input, \"unet_attention_residual.onnx\", opset_version=11)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LxD9ZjVkDDmo"
      },
      "source": [
        "##### To train, validate, and test the U-Net model on the Rain100L dataset \n",
        "1. Prepare the dataset and split it into training, validation, and test sets. \n",
        "2. Create the dataset loader for training, validation, and test sets.\n",
        "3. Train the model on the training set and validate on the validation set.\n",
        "4. Test the model on the test set, compute the evaluation metrics (PSNR and SSIM), and save the derained images.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cjA7OXRGDDmp"
      },
      "source": [
        "### training loop with gradient clipping for scaled gradients"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QYQ8nlVDDDmp",
        "outputId": "8296965a-82d3-4bdf-9499-85b68e485ab0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--- Training starts! ---\n",
            "Epoch 1/200 - Train loss: 0.123409, Val loss: 0.099265\n",
            "Epoch 1 - Training time: 7.4215 seconds, Validation time: 0.8307 seconds\n",
            "Epoch 2/200 - Train loss: 0.090032, Val loss: 0.074567\n",
            "Epoch 2 - Training time: 4.3328 seconds, Validation time: 0.7867 seconds\n",
            "Epoch 3/200 - Train loss: 0.063789, Val loss: 0.049942\n",
            "Epoch 3 - Training time: 4.3214 seconds, Validation time: 0.8013 seconds\n",
            "Epoch 4/200 - Train loss: 0.042109, Val loss: 0.035170\n",
            "Epoch 4 - Training time: 4.3373 seconds, Validation time: 0.8023 seconds\n",
            "Epoch 5/200 - Train loss: 0.028775, Val loss: 0.026896\n",
            "Epoch 5 - Training time: 4.3876 seconds, Validation time: 0.7992 seconds\n",
            "Epoch 6/200 - Train loss: 0.023156, Val loss: 0.020786\n",
            "Epoch 6 - Training time: 4.3705 seconds, Validation time: 0.8012 seconds\n",
            "Epoch 7/200 - Train loss: 0.015490, Val loss: 0.013247\n",
            "Epoch 7 - Training time: 4.3733 seconds, Validation time: 0.8172 seconds\n",
            "Epoch 8/200 - Train loss: 0.011530, Val loss: 0.010506\n",
            "Epoch 8 - Training time: 4.4111 seconds, Validation time: 0.8015 seconds\n",
            "Epoch 9/200 - Train loss: 0.009566, Val loss: 0.011122\n",
            "Epoch 9 - Training time: 4.4053 seconds, Validation time: 0.8014 seconds\n",
            "Epoch 10/200 - Train loss: 0.010114, Val loss: 0.010125\n",
            "Epoch 10 - Training time: 4.3610 seconds, Validation time: 0.8096 seconds\n",
            "Epoch 11/200 - Train loss: 0.009903, Val loss: 0.012226\n",
            "Epoch 11 - Training time: 4.4010 seconds, Validation time: 0.8022 seconds\n",
            "Epoch 12/200 - Train loss: 0.008805, Val loss: 0.008707\n",
            "Epoch 12 - Training time: 4.3947 seconds, Validation time: 0.7992 seconds\n",
            "Epoch 13/200 - Train loss: 0.008307, Val loss: 0.008491\n",
            "Epoch 13 - Training time: 4.3943 seconds, Validation time: 0.8032 seconds\n",
            "Epoch 14/200 - Train loss: 0.008067, Val loss: 0.009156\n",
            "Epoch 14 - Training time: 4.4306 seconds, Validation time: 0.8091 seconds\n",
            "Epoch 15/200 - Train loss: 0.007320, Val loss: 0.007636\n",
            "Epoch 15 - Training time: 4.4212 seconds, Validation time: 0.8117 seconds\n",
            "Epoch 16/200 - Train loss: 0.007082, Val loss: 0.007693\n",
            "Epoch 16 - Training time: 4.3925 seconds, Validation time: 0.8122 seconds\n",
            "Epoch 17/200 - Train loss: 0.006578, Val loss: 0.007594\n",
            "Epoch 17 - Training time: 4.3796 seconds, Validation time: 0.8084 seconds\n",
            "Epoch 18/200 - Train loss: 0.006269, Val loss: 0.006587\n",
            "Epoch 18 - Training time: 4.3598 seconds, Validation time: 0.7952 seconds\n",
            "Epoch 19/200 - Train loss: 0.005873, Val loss: 0.006138\n",
            "Epoch 19 - Training time: 4.3682 seconds, Validation time: 0.7972 seconds\n",
            "Epoch 20/200 - Train loss: 0.004957, Val loss: 0.006107\n",
            "Epoch 20 - Training time: 4.3641 seconds, Validation time: 0.8012 seconds\n",
            "Epoch 21/200 - Train loss: 0.004555, Val loss: 0.005014\n",
            "Epoch 21 - Training time: 4.3337 seconds, Validation time: 0.7959 seconds\n",
            "Epoch 22/200 - Train loss: 0.004155, Val loss: 0.005458\n",
            "Epoch 22 - Training time: 4.3765 seconds, Validation time: 0.7981 seconds\n",
            "Epoch 23/200 - Train loss: 0.004350, Val loss: 0.005862\n",
            "Epoch 23 - Training time: 4.3750 seconds, Validation time: 0.7982 seconds\n",
            "Epoch 24/200 - Train loss: 0.004059, Val loss: 0.004738\n",
            "Epoch 24 - Training time: 4.3394 seconds, Validation time: 0.8023 seconds\n",
            "Epoch 25/200 - Train loss: 0.004472, Val loss: 0.004738\n",
            "Epoch 25 - Training time: 4.3905 seconds, Validation time: 0.7944 seconds\n",
            "Epoch 26/200 - Train loss: 0.004085, Val loss: 0.005122\n",
            "Epoch 26 - Training time: 4.3732 seconds, Validation time: 0.7954 seconds\n",
            "Epoch 27/200 - Train loss: 0.004459, Val loss: 0.005210\n",
            "Epoch 27 - Training time: 4.3635 seconds, Validation time: 0.8025 seconds\n",
            "Epoch 28/200 - Train loss: 0.003844, Val loss: 0.004577\n",
            "Epoch 28 - Training time: 4.3928 seconds, Validation time: 0.8023 seconds\n",
            "Epoch 29/200 - Train loss: 0.003858, Val loss: 0.004650\n",
            "Epoch 29 - Training time: 4.3835 seconds, Validation time: 0.8008 seconds\n",
            "Epoch 30/200 - Train loss: 0.003612, Val loss: 0.004869\n",
            "Epoch 30 - Training time: 4.3862 seconds, Validation time: 0.8022 seconds\n",
            "Epoch 31/200 - Train loss: 0.003918, Val loss: 0.004741\n",
            "Epoch 31 - Training time: 4.3899 seconds, Validation time: 0.8053 seconds\n",
            "Epoch 32/200 - Train loss: 0.003606, Val loss: 0.004595\n",
            "Epoch 32 - Training time: 4.3729 seconds, Validation time: 0.8062 seconds\n",
            "Epoch 33/200 - Train loss: 0.003617, Val loss: 0.004898\n",
            "Epoch 33 - Training time: 4.3855 seconds, Validation time: 0.8052 seconds\n",
            "Epoch 34/200 - Train loss: 0.003739, Val loss: 0.004505\n",
            "Epoch 34 - Training time: 4.4014 seconds, Validation time: 0.8032 seconds\n",
            "Epoch 35/200 - Train loss: 0.003427, Val loss: 0.004434\n",
            "Epoch 35 - Training time: 4.3920 seconds, Validation time: 0.8092 seconds\n",
            "Epoch 36/200 - Train loss: 0.003785, Val loss: 0.005917\n",
            "Epoch 36 - Training time: 4.3897 seconds, Validation time: 0.8174 seconds\n",
            "Epoch 37/200 - Train loss: 0.004315, Val loss: 0.005557\n",
            "Epoch 37 - Training time: 4.4038 seconds, Validation time: 0.8062 seconds\n",
            "Epoch 38/200 - Train loss: 0.004110, Val loss: 0.004596\n",
            "Epoch 38 - Training time: 4.4081 seconds, Validation time: 0.8044 seconds\n",
            "Epoch 39/200 - Train loss: 0.003659, Val loss: 0.004511\n",
            "Epoch 39 - Training time: 4.3885 seconds, Validation time: 0.8054 seconds\n",
            "Epoch 40/200 - Train loss: 0.003557, Val loss: 0.004079\n",
            "Epoch 40 - Training time: 4.3955 seconds, Validation time: 0.8042 seconds\n",
            "Epoch 41/200 - Train loss: 0.003383, Val loss: 0.004252\n",
            "Epoch 41 - Training time: 4.3896 seconds, Validation time: 0.8026 seconds\n",
            "Epoch 42/200 - Train loss: 0.004015, Val loss: 0.004460\n",
            "Epoch 42 - Training time: 4.3820 seconds, Validation time: 0.8012 seconds\n",
            "Epoch 43/200 - Train loss: 0.003608, Val loss: 0.004471\n",
            "Epoch 43 - Training time: 4.4082 seconds, Validation time: 0.7974 seconds\n",
            "Epoch 44/200 - Train loss: 0.003534, Val loss: 0.004315\n",
            "Epoch 44 - Training time: 4.3952 seconds, Validation time: 0.8001 seconds\n",
            "Epoch 45/200 - Train loss: 0.003385, Val loss: 0.004302\n",
            "Epoch 45 - Training time: 4.4524 seconds, Validation time: 0.8062 seconds\n",
            "Epoch 46/200 - Train loss: 0.003334, Val loss: 0.004182\n",
            "Epoch 46 - Training time: 4.4237 seconds, Validation time: 0.8185 seconds\n",
            "Epoch 47/200 - Train loss: 0.003445, Val loss: 0.004329\n",
            "Epoch 47 - Training time: 4.5021 seconds, Validation time: 0.8302 seconds\n",
            "Epoch 48/200 - Train loss: 0.003336, Val loss: 0.004578\n",
            "Epoch 48 - Training time: 4.4593 seconds, Validation time: 0.8023 seconds\n",
            "Epoch 49/200 - Train loss: 0.003648, Val loss: 0.004233\n",
            "Epoch 49 - Training time: 4.4058 seconds, Validation time: 0.8055 seconds\n",
            "Epoch 50/200 - Train loss: 0.003389, Val loss: 0.004274\n",
            "Epoch 50 - Training time: 4.4006 seconds, Validation time: 0.8134 seconds\n",
            "Epoch 51/200 - Train loss: 0.003384, Val loss: 0.004242\n",
            "Epoch 51 - Training time: 4.4232 seconds, Validation time: 0.8072 seconds\n",
            "Epoch 52/200 - Train loss: 0.003371, Val loss: 0.003897\n",
            "Epoch 52 - Training time: 4.3848 seconds, Validation time: 0.7981 seconds\n",
            "Epoch 53/200 - Train loss: 0.003159, Val loss: 0.004343\n",
            "Epoch 53 - Training time: 4.3758 seconds, Validation time: 0.8036 seconds\n",
            "Epoch 54/200 - Train loss: 0.003383, Val loss: 0.003767\n",
            "Epoch 54 - Training time: 4.3816 seconds, Validation time: 0.8112 seconds\n",
            "Epoch 55/200 - Train loss: 0.002972, Val loss: 0.003791\n",
            "Epoch 55 - Training time: 4.3635 seconds, Validation time: 0.8004 seconds\n",
            "Epoch 56/200 - Train loss: 0.002855, Val loss: 0.003511\n",
            "Epoch 56 - Training time: 4.4108 seconds, Validation time: 0.8097 seconds\n",
            "Epoch 57/200 - Train loss: 0.003058, Val loss: 0.003907\n",
            "Epoch 57 - Training time: 4.4373 seconds, Validation time: 0.8122 seconds\n",
            "Epoch 58/200 - Train loss: 0.003268, Val loss: 0.003541\n",
            "Epoch 58 - Training time: 5.4898 seconds, Validation time: 0.8648 seconds\n",
            "Epoch 59/200 - Train loss: 0.002879, Val loss: 0.003772\n",
            "Epoch 59 - Training time: 4.4549 seconds, Validation time: 0.8093 seconds\n",
            "Epoch 60/200 - Train loss: 0.003048, Val loss: 0.003872\n",
            "Epoch 60 - Training time: 4.4167 seconds, Validation time: 0.8152 seconds\n",
            "Epoch 61/200 - Train loss: 0.002989, Val loss: 0.003761\n",
            "Epoch 61 - Training time: 4.4756 seconds, Validation time: 0.8152 seconds\n",
            "Epoch 62/200 - Train loss: 0.002996, Val loss: 0.003335\n",
            "Epoch 62 - Training time: 4.4155 seconds, Validation time: 0.8120 seconds\n",
            "Epoch 63/200 - Train loss: 0.004017, Val loss: 0.004284\n",
            "Epoch 63 - Training time: 4.3917 seconds, Validation time: 0.8065 seconds\n",
            "Epoch 64/200 - Train loss: 0.003637, Val loss: 0.004514\n",
            "Epoch 64 - Training time: 4.3992 seconds, Validation time: 0.8102 seconds\n",
            "Epoch 65/200 - Train loss: 0.003370, Val loss: 0.004103\n",
            "Epoch 65 - Training time: 4.4110 seconds, Validation time: 0.8104 seconds\n",
            "Epoch 66/200 - Train loss: 0.003047, Val loss: 0.003663\n",
            "Epoch 66 - Training time: 4.4385 seconds, Validation time: 0.8102 seconds\n",
            "Epoch 67/200 - Train loss: 0.002732, Val loss: 0.003326\n",
            "Epoch 67 - Training time: 4.4136 seconds, Validation time: 0.8114 seconds\n",
            "Epoch 68/200 - Train loss: 0.002652, Val loss: 0.003145\n",
            "Epoch 68 - Training time: 4.4327 seconds, Validation time: 0.8072 seconds\n",
            "Epoch 69/200 - Train loss: 0.002440, Val loss: 0.003227\n",
            "Epoch 69 - Training time: 4.4293 seconds, Validation time: 0.8062 seconds\n",
            "Epoch 70/200 - Train loss: 0.002439, Val loss: 0.003095\n",
            "Epoch 70 - Training time: 4.4104 seconds, Validation time: 0.8076 seconds\n",
            "Epoch 71/200 - Train loss: 0.002501, Val loss: 0.003152\n",
            "Epoch 71 - Training time: 4.4148 seconds, Validation time: 0.8110 seconds\n",
            "Epoch 72/200 - Train loss: 0.002670, Val loss: 0.003408\n",
            "Epoch 72 - Training time: 4.3961 seconds, Validation time: 0.8102 seconds\n",
            "Epoch 73/200 - Train loss: 0.002489, Val loss: 0.002928\n",
            "Epoch 73 - Training time: 4.4424 seconds, Validation time: 0.8092 seconds\n",
            "Epoch 74/200 - Train loss: 0.002342, Val loss: 0.002879\n",
            "Epoch 74 - Training time: 4.4111 seconds, Validation time: 0.8042 seconds\n",
            "Epoch 75/200 - Train loss: 0.002194, Val loss: 0.002776\n",
            "Epoch 75 - Training time: 4.4236 seconds, Validation time: 0.8082 seconds\n",
            "Epoch 76/200 - Train loss: 0.002228, Val loss: 0.002763\n",
            "Epoch 76 - Training time: 4.4199 seconds, Validation time: 0.8072 seconds\n",
            "Epoch 77/200 - Train loss: 0.002282, Val loss: 0.003350\n",
            "Epoch 77 - Training time: 4.3917 seconds, Validation time: 0.8078 seconds\n",
            "Epoch 78/200 - Train loss: 0.002844, Val loss: 0.002680\n",
            "Epoch 78 - Training time: 4.4202 seconds, Validation time: 0.8011 seconds\n",
            "Epoch 79/200 - Train loss: 0.002390, Val loss: 0.002587\n",
            "Epoch 79 - Training time: 4.4066 seconds, Validation time: 0.8064 seconds\n",
            "Epoch 80/200 - Train loss: 0.002457, Val loss: 0.002718\n",
            "Epoch 80 - Training time: 4.4115 seconds, Validation time: 0.8052 seconds\n",
            "Epoch 81/200 - Train loss: 0.002201, Val loss: 0.002713\n",
            "Epoch 81 - Training time: 4.4177 seconds, Validation time: 0.8032 seconds\n",
            "Epoch 82/200 - Train loss: 0.002147, Val loss: 0.002566\n",
            "Epoch 82 - Training time: 4.3808 seconds, Validation time: 0.8012 seconds\n",
            "Epoch 83/200 - Train loss: 0.002135, Val loss: 0.002517\n",
            "Epoch 83 - Training time: 4.4000 seconds, Validation time: 0.8004 seconds\n",
            "Epoch 84/200 - Train loss: 0.002067, Val loss: 0.002686\n",
            "Epoch 84 - Training time: 4.3739 seconds, Validation time: 0.8054 seconds\n",
            "Epoch 85/200 - Train loss: 0.002020, Val loss: 0.002651\n",
            "Epoch 85 - Training time: 4.3713 seconds, Validation time: 0.8072 seconds\n",
            "Epoch 86/200 - Train loss: 0.002087, Val loss: 0.002596\n",
            "Epoch 86 - Training time: 4.4095 seconds, Validation time: 0.8052 seconds\n",
            "Epoch 87/200 - Train loss: 0.002152, Val loss: 0.002612\n",
            "Epoch 87 - Training time: 4.3893 seconds, Validation time: 0.8011 seconds\n",
            "Epoch 88/200 - Train loss: 0.002002, Val loss: 0.002525\n",
            "Epoch 88 - Training time: 4.3790 seconds, Validation time: 0.8005 seconds\n",
            "Epoch 89/200 - Train loss: 0.002066, Val loss: 0.002515\n",
            "Epoch 89 - Training time: 4.3735 seconds, Validation time: 0.8003 seconds\n",
            "Epoch 90/200 - Train loss: 0.001994, Val loss: 0.002433\n",
            "Epoch 90 - Training time: 4.3907 seconds, Validation time: 0.7972 seconds\n",
            "Epoch 91/200 - Train loss: 0.001886, Val loss: 0.002534\n",
            "Epoch 91 - Training time: 4.3389 seconds, Validation time: 0.7992 seconds\n",
            "Epoch 92/200 - Train loss: 0.001977, Val loss: 0.002614\n",
            "Epoch 92 - Training time: 4.3755 seconds, Validation time: 0.7982 seconds\n",
            "Epoch 93/200 - Train loss: 0.002083, Val loss: 0.002657\n",
            "Epoch 93 - Training time: 4.3572 seconds, Validation time: 0.7992 seconds\n",
            "Epoch 94/200 - Train loss: 0.002176, Val loss: 0.002383\n",
            "Epoch 94 - Training time: 4.3661 seconds, Validation time: 0.8013 seconds\n",
            "Epoch 95/200 - Train loss: 0.002244, Val loss: 0.002653\n",
            "Epoch 95 - Training time: 4.3929 seconds, Validation time: 0.8002 seconds\n",
            "Epoch 96/200 - Train loss: 0.001964, Val loss: 0.002417\n",
            "Epoch 96 - Training time: 4.3671 seconds, Validation time: 0.8082 seconds\n",
            "Epoch 97/200 - Train loss: 0.002114, Val loss: 0.002773\n",
            "Epoch 97 - Training time: 4.3470 seconds, Validation time: 0.7965 seconds\n",
            "Epoch 98/200 - Train loss: 0.002150, Val loss: 0.002680\n",
            "Epoch 98 - Training time: 4.3803 seconds, Validation time: 0.8024 seconds\n",
            "Epoch 99/200 - Train loss: 0.002111, Val loss: 0.002784\n",
            "Epoch 99 - Training time: 4.4062 seconds, Validation time: 0.8019 seconds\n",
            "Epoch 100/200 - Train loss: 0.001991, Val loss: 0.002410\n",
            "Epoch 100 - Training time: 4.3975 seconds, Validation time: 0.8012 seconds\n",
            "Epoch 101/200 - Train loss: 0.001816, Val loss: 0.002409\n",
            "Epoch 101 - Training time: 4.3864 seconds, Validation time: 0.7912 seconds\n",
            "Epoch 102/200 - Train loss: 0.001879, Val loss: 0.002527\n",
            "Epoch 102 - Training time: 4.4103 seconds, Validation time: 0.7948 seconds\n",
            "Epoch 103/200 - Train loss: 0.001850, Val loss: 0.002311\n",
            "Epoch 103 - Training time: 4.3867 seconds, Validation time: 0.7977 seconds\n",
            "Epoch 104/200 - Train loss: 0.001878, Val loss: 0.002227\n",
            "Epoch 104 - Training time: 4.3669 seconds, Validation time: 0.7983 seconds\n",
            "Epoch 105/200 - Train loss: 0.002009, Val loss: 0.002587\n",
            "Epoch 105 - Training time: 4.4146 seconds, Validation time: 0.8022 seconds\n",
            "Epoch 106/200 - Train loss: 0.001924, Val loss: 0.002243\n",
            "Epoch 106 - Training time: 4.3793 seconds, Validation time: 0.7982 seconds\n",
            "Epoch 107/200 - Train loss: 0.001913, Val loss: 0.003102\n",
            "Epoch 107 - Training time: 4.4304 seconds, Validation time: 0.7921 seconds\n",
            "Epoch 108/200 - Train loss: 0.002688, Val loss: 0.002619\n",
            "Epoch 108 - Training time: 4.3666 seconds, Validation time: 0.7984 seconds\n",
            "Epoch 109/200 - Train loss: 0.002128, Val loss: 0.002577\n",
            "Epoch 109 - Training time: 4.3578 seconds, Validation time: 0.7944 seconds\n",
            "Epoch 110/200 - Train loss: 0.002166, Val loss: 0.003099\n",
            "Epoch 110 - Training time: 4.3862 seconds, Validation time: 0.8022 seconds\n",
            "Epoch 111/200 - Train loss: 0.002144, Val loss: 0.002559\n",
            "Epoch 111 - Training time: 4.3548 seconds, Validation time: 0.7934 seconds\n",
            "Epoch 112/200 - Train loss: 0.001906, Val loss: 0.002739\n",
            "Epoch 112 - Training time: 4.3657 seconds, Validation time: 0.7934 seconds\n",
            "Epoch 113/200 - Train loss: 0.002194, Val loss: 0.002825\n",
            "Epoch 113 - Training time: 4.3739 seconds, Validation time: 0.7916 seconds\n",
            "Epoch 114/200 - Train loss: 0.002040, Val loss: 0.002339\n",
            "Epoch 114 - Training time: 4.3564 seconds, Validation time: 0.8032 seconds\n",
            "Epoch 115/200 - Train loss: 0.001869, Val loss: 0.002203\n",
            "Epoch 115 - Training time: 4.3422 seconds, Validation time: 0.7978 seconds\n",
            "Epoch 116/200 - Train loss: 0.001676, Val loss: 0.002308\n",
            "Epoch 116 - Training time: 4.3853 seconds, Validation time: 0.7972 seconds\n",
            "Epoch 117/200 - Train loss: 0.001837, Val loss: 0.002431\n",
            "Epoch 117 - Training time: 4.3884 seconds, Validation time: 0.7975 seconds\n",
            "Epoch 118/200 - Train loss: 0.001896, Val loss: 0.002550\n",
            "Epoch 118 - Training time: 4.3723 seconds, Validation time: 0.7942 seconds\n",
            "Epoch 119/200 - Train loss: 0.002025, Val loss: 0.003305\n",
            "Epoch 119 - Training time: 4.3424 seconds, Validation time: 0.7998 seconds\n",
            "Epoch 120/200 - Train loss: 0.002310, Val loss: 0.002732\n",
            "Epoch 120 - Training time: 4.3781 seconds, Validation time: 0.7938 seconds\n",
            "Epoch 121/200 - Train loss: 0.001914, Val loss: 0.002243\n",
            "Epoch 121 - Training time: 4.3951 seconds, Validation time: 0.8012 seconds\n",
            "Epoch 122/200 - Train loss: 0.001796, Val loss: 0.003130\n",
            "Epoch 122 - Training time: 4.3890 seconds, Validation time: 0.7982 seconds\n",
            "Epoch 123/200 - Train loss: 0.002451, Val loss: 0.002428\n",
            "Epoch 123 - Training time: 4.3537 seconds, Validation time: 0.7962 seconds\n",
            "Epoch 124/200 - Train loss: 0.002069, Val loss: 0.002904\n",
            "Epoch 124 - Training time: 4.3564 seconds, Validation time: 0.7955 seconds\n",
            "Epoch 125/200 - Train loss: 0.002318, Val loss: 0.002541\n",
            "Epoch 125 - Training time: 4.3840 seconds, Validation time: 0.7958 seconds\n",
            "Epoch 126/200 - Train loss: 0.002178, Val loss: 0.002579\n",
            "Epoch 126 - Training time: 4.3693 seconds, Validation time: 0.8032 seconds\n",
            "Epoch 127/200 - Train loss: 0.002150, Val loss: 0.002325\n",
            "Epoch 127 - Training time: 4.3991 seconds, Validation time: 0.8055 seconds\n",
            "Epoch 128/200 - Train loss: 0.001945, Val loss: 0.002439\n",
            "Epoch 128 - Training time: 4.3719 seconds, Validation time: 0.7991 seconds\n",
            "Epoch 129/200 - Train loss: 0.001952, Val loss: 0.002347\n",
            "Epoch 129 - Training time: 4.3930 seconds, Validation time: 0.8015 seconds\n",
            "Epoch 130/200 - Train loss: 0.001765, Val loss: 0.002425\n",
            "Epoch 130 - Training time: 4.3670 seconds, Validation time: 0.7982 seconds\n",
            "Epoch 131/200 - Train loss: 0.001884, Val loss: 0.002380\n",
            "Epoch 131 - Training time: 4.3762 seconds, Validation time: 0.7993 seconds\n",
            "Epoch 132/200 - Train loss: 0.001754, Val loss: 0.002315\n",
            "Epoch 132 - Training time: 4.3799 seconds, Validation time: 0.7946 seconds\n",
            "Epoch 133/200 - Train loss: 0.001685, Val loss: 0.002172\n",
            "Epoch 133 - Training time: 4.3541 seconds, Validation time: 0.7983 seconds\n",
            "Epoch 134/200 - Train loss: 0.001727, Val loss: 0.002151\n",
            "Epoch 134 - Training time: 4.3819 seconds, Validation time: 0.7992 seconds\n",
            "Epoch 135/200 - Train loss: 0.001754, Val loss: 0.002268\n",
            "Epoch 135 - Training time: 4.3554 seconds, Validation time: 0.8005 seconds\n",
            "Epoch 136/200 - Train loss: 0.001831, Val loss: 0.002599\n",
            "Epoch 136 - Training time: 4.3787 seconds, Validation time: 0.8022 seconds\n",
            "Epoch 137/200 - Train loss: 0.002355, Val loss: 0.002473\n",
            "Epoch 137 - Training time: 4.3845 seconds, Validation time: 0.8012 seconds\n",
            "Epoch 138/200 - Train loss: 0.001961, Val loss: 0.002408\n",
            "Epoch 138 - Training time: 4.3752 seconds, Validation time: 0.7942 seconds\n",
            "Epoch 139/200 - Train loss: 0.002076, Val loss: 0.002993\n",
            "Epoch 139 - Training time: 4.3979 seconds, Validation time: 0.7976 seconds\n",
            "Epoch 140/200 - Train loss: 0.002274, Val loss: 0.003241\n",
            "Epoch 140 - Training time: 4.3623 seconds, Validation time: 0.8042 seconds\n",
            "Epoch 141/200 - Train loss: 0.002153, Val loss: 0.002757\n",
            "Epoch 141 - Training time: 4.3807 seconds, Validation time: 0.8062 seconds\n",
            "Epoch 142/200 - Train loss: 0.001956, Val loss: 0.002455\n",
            "Epoch 142 - Training time: 4.4101 seconds, Validation time: 0.8002 seconds\n",
            "Epoch 143/200 - Train loss: 0.001809, Val loss: 0.002819\n",
            "Epoch 143 - Training time: 4.3972 seconds, Validation time: 0.8022 seconds\n",
            "Epoch 144/200 - Train loss: 0.001919, Val loss: 0.002210\n",
            "Epoch 144 - Training time: 4.3897 seconds, Validation time: 0.7972 seconds\n",
            "Epoch 145/200 - Train loss: 0.001605, Val loss: 0.002204\n",
            "Epoch 145 - Training time: 4.3745 seconds, Validation time: 0.7982 seconds\n",
            "Epoch 146/200 - Train loss: 0.001694, Val loss: 0.002073\n",
            "Epoch 146 - Training time: 4.3598 seconds, Validation time: 0.8027 seconds\n",
            "Epoch 147/200 - Train loss: 0.001900, Val loss: 0.002046\n",
            "Epoch 147 - Training time: 4.3480 seconds, Validation time: 0.7989 seconds\n",
            "Epoch 148/200 - Train loss: 0.001541, Val loss: 0.002185\n",
            "Epoch 148 - Training time: 4.4011 seconds, Validation time: 0.8032 seconds\n",
            "Epoch 149/200 - Train loss: 0.001557, Val loss: 0.002150\n",
            "Epoch 149 - Training time: 4.3955 seconds, Validation time: 0.8122 seconds\n",
            "Epoch 150/200 - Train loss: 0.001667, Val loss: 0.001996\n",
            "Epoch 150 - Training time: 4.4021 seconds, Validation time: 0.7997 seconds\n",
            "Epoch 151/200 - Train loss: 0.001773, Val loss: 0.002144\n",
            "Epoch 151 - Training time: 4.3371 seconds, Validation time: 0.7973 seconds\n",
            "Epoch 152/200 - Train loss: 0.001769, Val loss: 0.002007\n",
            "Epoch 152 - Training time: 4.3608 seconds, Validation time: 0.8010 seconds\n",
            "Epoch 153/200 - Train loss: 0.001844, Val loss: 0.002097\n",
            "Epoch 153 - Training time: 4.3763 seconds, Validation time: 0.7982 seconds\n",
            "Epoch 154/200 - Train loss: 0.001719, Val loss: 0.002480\n",
            "Epoch 154 - Training time: 4.4079 seconds, Validation time: 0.8042 seconds\n",
            "Epoch 155/200 - Train loss: 0.001886, Val loss: 0.002252\n",
            "Epoch 155 - Training time: 4.3696 seconds, Validation time: 0.8002 seconds\n",
            "Epoch 156/200 - Train loss: 0.001557, Val loss: 0.001959\n",
            "Epoch 156 - Training time: 4.3889 seconds, Validation time: 0.8042 seconds\n",
            "Epoch 157/200 - Train loss: 0.001550, Val loss: 0.002224\n",
            "Epoch 157 - Training time: 4.3996 seconds, Validation time: 0.7932 seconds\n",
            "Epoch 158/200 - Train loss: 0.001596, Val loss: 0.002125\n",
            "Epoch 158 - Training time: 4.4057 seconds, Validation time: 0.7987 seconds\n",
            "Epoch 159/200 - Train loss: 0.001461, Val loss: 0.001955\n",
            "Epoch 159 - Training time: 4.3907 seconds, Validation time: 0.8053 seconds\n",
            "Epoch 160/200 - Train loss: 0.001536, Val loss: 0.001947\n",
            "Epoch 160 - Training time: 4.4260 seconds, Validation time: 0.8045 seconds\n",
            "Epoch 161/200 - Train loss: 0.001603, Val loss: 0.002541\n",
            "Epoch 161 - Training time: 4.3946 seconds, Validation time: 0.8042 seconds\n",
            "Epoch 162/200 - Train loss: 0.001723, Val loss: 0.001949\n",
            "Epoch 162 - Training time: 4.3560 seconds, Validation time: 0.8052 seconds\n",
            "Epoch 163/200 - Train loss: 0.001530, Val loss: 0.001882\n",
            "Epoch 163 - Training time: 4.3943 seconds, Validation time: 0.8048 seconds\n",
            "Epoch 164/200 - Train loss: 0.001454, Val loss: 0.001905\n",
            "Epoch 164 - Training time: 4.4343 seconds, Validation time: 0.8055 seconds\n",
            "Epoch 165/200 - Train loss: 0.001511, Val loss: 0.002079\n",
            "Epoch 165 - Training time: 4.3782 seconds, Validation time: 0.8042 seconds\n",
            "Epoch 166/200 - Train loss: 0.001478, Val loss: 0.001996\n",
            "Epoch 166 - Training time: 4.3966 seconds, Validation time: 0.8036 seconds\n",
            "Epoch 167/200 - Train loss: 0.001470, Val loss: 0.002131\n",
            "Epoch 167 - Training time: 4.4014 seconds, Validation time: 0.8022 seconds\n",
            "Epoch 168/200 - Train loss: 0.001644, Val loss: 0.002435\n",
            "Epoch 168 - Training time: 4.4719 seconds, Validation time: 0.8121 seconds\n",
            "Epoch 169/200 - Train loss: 0.001749, Val loss: 0.002029\n",
            "Epoch 169 - Training time: 4.4698 seconds, Validation time: 0.8112 seconds\n",
            "Epoch 170/200 - Train loss: 0.001608, Val loss: 0.002096\n",
            "Epoch 170 - Training time: 4.4199 seconds, Validation time: 0.8065 seconds\n",
            "Epoch 171/200 - Train loss: 0.001644, Val loss: 0.002057\n",
            "Epoch 171 - Training time: 4.4503 seconds, Validation time: 0.8089 seconds\n",
            "Epoch 172/200 - Train loss: 0.001575, Val loss: 0.002002\n",
            "Epoch 172 - Training time: 4.3975 seconds, Validation time: 0.8002 seconds\n",
            "Epoch 173/200 - Train loss: 0.001489, Val loss: 0.002172\n",
            "Epoch 173 - Training time: 4.3909 seconds, Validation time: 0.8001 seconds\n",
            "Epoch 174/200 - Train loss: 0.001618, Val loss: 0.002079\n",
            "Epoch 174 - Training time: 4.3895 seconds, Validation time: 0.8045 seconds\n",
            "Epoch 175/200 - Train loss: 0.001558, Val loss: 0.001865\n",
            "Epoch 175 - Training time: 4.3720 seconds, Validation time: 0.7986 seconds\n",
            "Epoch 176/200 - Train loss: 0.001417, Val loss: 0.001926\n",
            "Epoch 176 - Training time: 4.4062 seconds, Validation time: 0.8038 seconds\n",
            "Epoch 177/200 - Train loss: 0.001398, Val loss: 0.001860\n",
            "Epoch 177 - Training time: 4.3953 seconds, Validation time: 0.8067 seconds\n",
            "Epoch 178/200 - Train loss: 0.001433, Val loss: 0.001860\n",
            "Epoch 178 - Training time: 4.4215 seconds, Validation time: 0.8064 seconds\n",
            "Epoch 179/200 - Train loss: 0.001558, Val loss: 0.002016\n",
            "Epoch 179 - Training time: 4.3770 seconds, Validation time: 0.8018 seconds\n",
            "Epoch 180/200 - Train loss: 0.001449, Val loss: 0.001933\n",
            "Epoch 180 - Training time: 4.3761 seconds, Validation time: 0.7997 seconds\n",
            "Epoch 181/200 - Train loss: 0.001384, Val loss: 0.001921\n",
            "Epoch 181 - Training time: 4.3758 seconds, Validation time: 0.8047 seconds\n",
            "Epoch 182/200 - Train loss: 0.001564, Val loss: 0.002343\n",
            "Epoch 182 - Training time: 4.3571 seconds, Validation time: 0.8052 seconds\n",
            "Epoch 183/200 - Train loss: 0.001635, Val loss: 0.001957\n",
            "Epoch 183 - Training time: 4.3798 seconds, Validation time: 0.8022 seconds\n",
            "Epoch 184/200 - Train loss: 0.001468, Val loss: 0.001893\n",
            "Epoch 184 - Training time: 4.3873 seconds, Validation time: 0.7959 seconds\n",
            "Epoch 185/200 - Train loss: 0.001396, Val loss: 0.001897\n",
            "Epoch 185 - Training time: 4.3806 seconds, Validation time: 0.7992 seconds\n",
            "Epoch 186/200 - Train loss: 0.001444, Val loss: 0.002131\n",
            "Epoch 186 - Training time: 4.3657 seconds, Validation time: 0.8052 seconds\n",
            "Epoch 187/200 - Train loss: 0.001575, Val loss: 0.002041\n",
            "Epoch 187 - Training time: 4.3674 seconds, Validation time: 0.8068 seconds\n",
            "Epoch 188/200 - Train loss: 0.001440, Val loss: 0.001768\n",
            "Epoch 188 - Training time: 4.3736 seconds, Validation time: 0.7972 seconds\n",
            "Epoch 189/200 - Train loss: 0.001432, Val loss: 0.001899\n",
            "Epoch 189 - Training time: 4.3845 seconds, Validation time: 0.8002 seconds\n",
            "Epoch 190/200 - Train loss: 0.001409, Val loss: 0.002045\n",
            "Epoch 190 - Training time: 4.3640 seconds, Validation time: 0.7993 seconds\n",
            "Epoch 191/200 - Train loss: 0.001564, Val loss: 0.002188\n",
            "Epoch 191 - Training time: 4.4051 seconds, Validation time: 0.8055 seconds\n",
            "Epoch 192/200 - Train loss: 0.001664, Val loss: 0.002089\n",
            "Epoch 192 - Training time: 4.3519 seconds, Validation time: 0.7982 seconds\n",
            "Epoch 193/200 - Train loss: 0.001645, Val loss: 0.001910\n",
            "Epoch 193 - Training time: 4.3586 seconds, Validation time: 0.7982 seconds\n",
            "Epoch 194/200 - Train loss: 0.001841, Val loss: 0.001914\n",
            "Epoch 194 - Training time: 4.3492 seconds, Validation time: 0.7994 seconds\n",
            "Epoch 195/200 - Train loss: 0.002315, Val loss: 0.002380\n",
            "Epoch 195 - Training time: 4.3954 seconds, Validation time: 0.8002 seconds\n",
            "Epoch 196/200 - Train loss: 0.002158, Val loss: 0.002898\n",
            "Epoch 196 - Training time: 4.3680 seconds, Validation time: 0.8008 seconds\n",
            "Epoch 197/200 - Train loss: 0.002006, Val loss: 0.002327\n",
            "Epoch 197 - Training time: 4.3555 seconds, Validation time: 0.8026 seconds\n",
            "Epoch 198/200 - Train loss: 0.001823, Val loss: 0.002151\n",
            "Epoch 198 - Training time: 4.4064 seconds, Validation time: 0.8043 seconds\n",
            "Epoch 199/200 - Train loss: 0.001581, Val loss: 0.001976\n",
            "Epoch 199 - Training time: 4.3761 seconds, Validation time: 0.7952 seconds\n",
            "Epoch 200/200 - Train loss: 0.001524, Val loss: 0.002083\n",
            "Epoch 200 - Training time: 4.3631 seconds, Validation time: 0.8002 seconds\n",
            "Training time: 1042.7204 seconds\n"
          ]
        }
      ],
      "source": [
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "unet = UNet(3, 3).to(device)\n",
        "criterion = nn.MSELoss()\n",
        "optimizer = optim.Adam(unet.parameters(), lr=0.001)\n",
        "\n",
        "num_epochs = 200\n",
        "\n",
        "# Initialize gradient scaler for mixed-precision training\n",
        "scaler = GradScaler()\n",
        "accumulation_steps = 4\n",
        "\n",
        "# Initialize lists to store train and validation losses\n",
        "train_losses = []\n",
        "val_losses = []\n",
        "\n",
        "clip_value = 1.0  # Adjust this value as needed\n",
        "\n",
        "print('--- Training starts! ---')\n",
        "start_time_train = time.time()\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    unet.train()\n",
        "    train_loss = 0.0\n",
        "\n",
        "    start_time_train_epoch = time.time()\n",
        "    \n",
        "    optimizer.zero_grad()\n",
        "    \n",
        "    for step, (rain, norain) in enumerate(train_loader):\n",
        "        rain = rain.to(device)\n",
        "        norain = norain.to(device)\n",
        "\n",
        "        # Use autocast for mixed-precision training\n",
        "        with autocast():\n",
        "            output = unet(rain)\n",
        "            loss = criterion(output, norain)\n",
        "        \n",
        "        # Scale the loss and backpropagate\n",
        "        scaler.scale(loss).backward()\n",
        "\n",
        "        # Apply gradient clipping to the scaled gradients\n",
        "        if clip_value is not None:\n",
        "            torch.nn.utils.clip_grad_norm_(unet.parameters(), clip_value, norm_type=2)\n",
        "        \n",
        "        if (step + 1) % accumulation_steps == 0:\n",
        "            # Update the model weights and optimizer state\n",
        "            scaler.step(optimizer)\n",
        "            scaler.update()\n",
        "            optimizer.zero_grad()\n",
        "        \n",
        "        train_loss += loss.item()\n",
        "    \n",
        "    # Calculate the average loss for the epoch and append it to the list\n",
        "    train_losses.append(train_loss/len(train_loader))\n",
        "\n",
        "    end_time_train_epoch = time.time() - start_time_train_epoch\n",
        "    \n",
        "    unet.eval()\n",
        "    val_loss = 0.0\n",
        "    \n",
        "    start_time_val_epoch = time.time()\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for rain, norain in val_loader:\n",
        "            rain = rain.to(device)\n",
        "            norain = norain.to(device)\n",
        "\n",
        "            with autocast():\n",
        "                output = unet(rain)\n",
        "                loss = criterion(output, norain)\n",
        "\n",
        "            val_loss += loss.item()\n",
        "\n",
        "    val_losses.append(val_loss/len(val_loader))\n",
        "    end_time_val_epoch = time.time() - start_time_val_epoch\n",
        "\n",
        "    print(f\"Epoch {epoch+1}/{num_epochs} - Train loss: {train_losses[-1]:.6f}, Val loss: {val_losses[-1]:.6f}\")\n",
        "    print(f\"Epoch {epoch+1} - Training time: {end_time_train_epoch:.4f} seconds, Validation time: {end_time_val_epoch:.4f} seconds\")\n",
        "\n",
        "end_time_train = time.time() - start_time_train\n",
        "print('Training time: {0:.4f} seconds'.format(end_time_train))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WyHdVvzNDDmq",
        "outputId": "c38db424-a602-4bc7-c6ff-67788130fd5c"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "plt.figure()\n",
        "plt.plot(train_losses, label='Train Loss')\n",
        "plt.plot(val_losses, label='Validation Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "plt.title('Train and Validation Loss per Epoch')\n",
        "plt.savefig('train_val_loss_plot.png')\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e2ELaO3ADDmq",
        "outputId": "54291536-d31d-46e6-829e-35538f907dd8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--- Testing starts! ---\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\labuser\\AppData\\Local\\Temp\\ipykernel_19984\\1426726481.py:29: FutureWarning: `multichannel` is a deprecated argument name for `structural_similarity`. It will be removed in version 1.0. Please use `channel_axis` instead.\n",
            "  cur_ssim = ssim(norain[j], output[j], data_range=1, multichannel=True)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Average PSNR: 28.626849 (std: 2.371599), Average SSIM: 0.882890 (std: 0.077245)\n"
          ]
        }
      ],
      "source": [
        "# Test the model and save derained images\n",
        "print('--- Testing starts! ---')\n",
        "start_time_test = time.time()\n",
        "\n",
        "unet.eval()\n",
        "test_psnr = 0.0\n",
        "test_ssim = 0.0\n",
        "output_path = \"G:\\My Drive\\Deraining\\Rain100L\\derained\"\n",
        "if not os.path.exists(output_path):\n",
        "    os.makedirs(output_path)\n",
        "metrics = []\n",
        "with torch.no_grad():\n",
        "    img_count = 1\n",
        "    for i, (rain, norain) in enumerate(test_loader):\n",
        "        rain = rain.to(device)\n",
        "        norain = norain.to(device)\n",
        "\n",
        "        output = unet(rain)\n",
        "        output = output.cpu().numpy().transpose((0, 2, 3, 1)).clip(0, 1)\n",
        "        norain = norain.cpu().numpy().transpose((0, 2, 3, 1)).clip(0, 1)\n",
        "\n",
        "        for j in range(output.shape[0]):\n",
        "            # Save the derained image\n",
        "            output_img = Image.fromarray((output[j] * 255).astype(np.uint8))\n",
        "            output_img.save(os.path.join(output_path, f\"derained_{img_count}.png\"))\n",
        "\n",
        "            # Compute PSNR and SSIM\n",
        "            cur_psnr = psnr(norain[j], output[j], data_range=1)\n",
        "            cur_ssim = ssim(norain[j], output[j], data_range=1, multichannel=True)\n",
        "\n",
        "            metrics.append([cur_psnr, cur_ssim])\n",
        "            img_count += 1\n",
        "\n",
        "# Save the metrics to a CSV file and compute the average and standard deviation\n",
        "metrics_df = pd.DataFrame(metrics, columns=[\"PSNR\", \"SSIM\"])\n",
        "metrics_df.to_csv(\"metrics.csv\", index=False)\n",
        "\n",
        "mean_psnr = metrics_df[\"PSNR\"].mean()\n",
        "mean_ssim = metrics_df[\"SSIM\"].mean()\n",
        "std_psnr = metrics_df[\"PSNR\"].std()\n",
        "std_ssim = metrics_df[\"SSIM\"].std()\n",
        "\n",
        "print(f\"Average PSNR: {mean_psnr:.6f} (std: {std_psnr:.6f}), Average SSIM: {mean_ssim:.6f} (std: {std_ssim:.6f})\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.11"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}