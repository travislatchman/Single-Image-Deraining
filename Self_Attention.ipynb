{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNbcCy1vdLQ6vr+DRgVI2Bz",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/travislatchman/Single-Image-Deraining/blob/main/Self_Attention.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# (THESE WERE NOT USED) - INITIAL IDEAS FOR SELF-ATTENTION"
      ],
      "metadata": {
        "id": "gPCPDHaYI3o4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn.functional as F\n",
        "import torch\n",
        "import torch.nn as nn"
      ],
      "metadata": {
        "id": "qJmZYb8Y8aMg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# U-Net + Self-Attention"
      ],
      "metadata": {
        "id": "XOLKlXdP855y"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Add a self-attention layer after each convolutional layer in the encoder and decoder parts of the U-Net. By adding self-attention layers, the U-Net model could have the ability to capture long-range dependencies and focus on important regions in the input, which may lead to improved deraining performance. However, adding self-attention mechanisms increased the model's complexity and computational cost."
      ],
      "metadata": {
        "id": "X2sVtG6NtvxY"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iP00AQ3LtOaU"
      },
      "outputs": [],
      "source": [
        "class SelfAttention(nn.Module):\n",
        "    def __init__(self, in_channels):\n",
        "        super(SelfAttention, self).__init__()\n",
        "        self.query_conv = nn.Conv2d(in_channels, in_channels // 8, kernel_size=1)\n",
        "        self.key_conv = nn.Conv2d(in_channels, in_channels // 8, kernel_size=1)\n",
        "        self.value_conv = nn.Conv2d(in_channels, in_channels, kernel_size=1)\n",
        "        self.gamma = nn.Parameter(torch.zeros(1))\n",
        "\n",
        "    def forward(self, x):\n",
        "        batch_size, _, height, width = x.size()\n",
        "        query = self.query_conv(x).view(batch_size, -1, height * width).permute(0, 2, 1)\n",
        "        key = self.key_conv(x).view(batch_size, -1, height * width)\n",
        "        energy = torch.bmm(query, key)\n",
        "        attention = F.softmax(energy, dim=-1)\n",
        "        value = self.value_conv(x).view(batch_size, -1, height * width)\n",
        "        out = torch.bmm(value, attention.permute(0, 2, 1))\n",
        "        out = out.view(batch_size, -1, height, width)\n",
        "        out = self.gamma * out + x\n",
        "        return out"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class UNet(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels):\n",
        "        super(UNet, self).__init__()\n",
        "\n",
        "        def conv_block(in_channels, out_channels):\n",
        "            return nn.Sequential(\n",
        "                nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1),\n",
        "                nn.ReLU(inplace=True),\n",
        "                SelfAttention(out_channels),\n",
        "                nn.Conv2d(out_channels, out_channels, kernel_size=3, padding=1),\n",
        "                nn.ReLU(inplace=True),\n",
        "                SelfAttention(out_channels)\n",
        "            )\n",
        "\n",
        "\n",
        "        def up_block(in_channels, out_channels):\n",
        "            return nn.Sequential(\n",
        "                nn.ConvTranspose2d(in_channels, out_channels, kernel_size=2, stride=2),\n",
        "                nn.ReLU(inplace=True)\n",
        "            )\n",
        "\n",
        "        self.enc1 = conv_block(in_channels, 64)\n",
        "        self.enc2 = conv_block(64, 128)\n",
        "        self.enc3 = conv_block(128, 256)\n",
        "        self.enc4 = conv_block(256, 512)\n",
        "\n",
        "        self.pool = nn.MaxPool2d(2)\n",
        "        \n",
        "        self.middle = conv_block(512, 1024)\n",
        "\n",
        "        self.up4 = up_block(1024, 512)\n",
        "        self.dec4 = conv_block(1024, 512)\n",
        "        self.up3 = up_block(512, 256)\n",
        "        self.dec3 = conv_block(512, 256)\n",
        "        self.up2 = up_block(256, 128)\n",
        "        self.dec2 = conv_block(256, 128)\n",
        "\n",
        "        self.up1 = nn.ConvTranspose2d(128, 64, kernel_size=2, stride=2)\n",
        "        self.dec1 = conv_block(128, 64)\n",
        "\n",
        "        self.output = nn.Conv2d(64, out_channels, kernel_size=1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        enc1 = self.enc1(x)\n",
        "        enc2 = self.enc2(self.pool(enc1))\n",
        "        enc3 = self.enc3(self.pool(enc2))\n",
        "        enc4 = self.enc4(self.pool(enc3))\n",
        "\n",
        "        middle = self.middle(self.pool(enc4))\n",
        "\n",
        "        up4 = self.up4(middle)\n",
        "        merge4 = torch.cat([enc4, up4], dim=1)\n",
        "        dec4 = self.dec4(merge4)\n",
        "\n",
        "        up3 = self.up3(dec4)\n",
        "        merge3 = torch.cat([enc3, up3], dim=1)\n",
        "        dec3 = self.dec3(merge3)\n",
        "\n",
        "        up2 = self.up2(dec3)\n",
        "        merge2 = torch.cat([enc2, up2], dim=1)\n",
        "        dec2 = self.dec2(merge2)\n",
        "\n",
        "        up1 = self.up1(dec2)\n",
        "        merge1 = torch.cat([enc1, up1], dim=1)\n",
        "        dec1 = self.dec1(merge1)\n",
        "\n",
        "        output = self.output(dec1)\n",
        "        return output\n",
        "\n",
        "unet = UNet(3, 3)  # Adjust input and output channels to 3 for RGB images"
      ],
      "metadata": {
        "id": "ZBtM09_O8rba"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# U-Net + Self-Attention + Residual"
      ],
      "metadata": {
        "id": "OJlxJkIhDw2X"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "integrate both residual blocks and self-attention mechanisms into a U-Net architecture. The ResidualBlock class includes a self-attention mechanism, which is applied after the second convolution layer before the residual connection. The encoder and decoder blocks are then replaced with these modified residual blocks."
      ],
      "metadata": {
        "id": "i_J1xQ4VETob"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class SelfAttention(nn.Module):\n",
        "    def __init__(self, in_channels):\n",
        "        super(SelfAttention, self).__init__()\n",
        "        self.query = nn.Conv2d(in_channels, in_channels // 8, kernel_size=1)\n",
        "        self.key = nn.Conv2d(in_channels, in_channels // 8, kernel_size=1)\n",
        "        self.value = nn.Conv2d(in_channels, in_channels, kernel_size=1)\n",
        "        self.gamma = nn.Parameter(torch.zeros(1))\n",
        "\n",
        "    def forward(self, x):\n",
        "        batch_size, channels, height, width = x.size()\n",
        "        query = self.query(x).view(batch_size, -1, height * width).permute(0, 2, 1)\n",
        "        key = self.key(x).view(batch_size, -1, height * width)\n",
        "        attention = torch.softmax(torch.bmm(query, key), dim=-1)\n",
        "        value = self.value(x).view(batch_size, -1, height * width)\n",
        "        out = torch.bmm(value, attention.permute(0, 2, 1)).view(batch_size, channels, height, width)\n",
        "        return self.gamma * out + x\n",
        "\n",
        "class ResidualBlock(nn.Module):\n",
        "    def __init__(self, in_channels):\n",
        "        super(ResidualBlock, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(in_channels, in_channels, kernel_size=3, padding=1)\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "        self.conv2 = nn.Conv2d(in_channels, in_channels, kernel_size=3, padding=1)\n",
        "        self.attention = SelfAttention(in_channels)\n",
        "\n",
        "    def forward(self, x):\n",
        "        residual = x\n",
        "        out = self.relu(self.conv1(x))\n",
        "        out = self.conv2(out)\n",
        "        out = self.attention(out)\n",
        "        return out + residual\n",
        "\n",
        "\n",
        "class UNetWithResidualAndAttention(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels):\n",
        "        super(UNetWithResidualAndAttention, self).__init__()\n",
        "        \n",
        "        # ... (other layers such as encoders, decoders, and upsampling)\n",
        "\n",
        "        self.enc1 = ResidualBlock(64)\n",
        "        self.enc2 = ResidualBlock(128)\n",
        "        self.enc3 = ResidualBlock(256)\n",
        "        self.enc4 = ResidualBlock(512)\n",
        "\n",
        "        self.middle = ResidualBlock(1024)\n",
        "\n",
        "        self.dec4 = ResidualBlock(512)\n",
        "        self.dec3 = ResidualBlock(256)\n",
        "        self.dec2 = ResidualBlock(128)\n",
        "        self.dec1 = ResidualBlock(64)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # ... (forward pass with the modified architecture)\n",
        "\n",
        "unet = UNetWithResidualAndAttention(3, 3)\n",
        "\n"
      ],
      "metadata": {
        "id": "Zbooa2ZuD9CS"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}