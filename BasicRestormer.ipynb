{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyME1HP9iX+H/zmGPi41nhW7",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/travislatchman/Single-Image-Deraining/blob/main/BasicRestormer.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### he original Restormer model is quite complex and contains many components. In this basic version, I've simplified the architecture by using fewer Transformer blocks and eliminating the downsampling and upsampling layers. This should make the model easier to train and understand, while still providing reasonable performance for single-image deraining tasks."
      ],
      "metadata": {
        "id": "NILU-aMvyJpS"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "soX4-J4Hx8Oe"
      },
      "outputs": [],
      "source": [
        "class BasicRestormer(nn.Module):\n",
        "    def __init__(self, num_blocks=4, num_heads=4, channels=48, expansion_factor=2):\n",
        "        super(BasicRestormer, self).__init__()\n",
        "\n",
        "        self.embed_conv = nn.Conv2d(3, channels, kernel_size=3, padding=1, bias=False)\n",
        "\n",
        "        self.transformer_blocks = nn.Sequential(*[TransformerBlock(\n",
        "            channels, num_heads, expansion_factor) for _ in range(num_blocks)])\n",
        "\n",
        "        self.output = nn.Conv2d(channels, 3, kernel_size=3, padding=1, bias=False)\n",
        "\n",
        "    def forward(self, x):\n",
        "        fo = self.embed_conv(x)\n",
        "        ft = self.transformer_blocks(fo)\n",
        "        out = self.output(ft) + x\n",
        "        return out"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### enhance the Restormer model with Residual Connections"
      ],
      "metadata": {
        "id": "FvjrUYZmyUQ0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class ResidualTransformerBlock(nn.Module):\n",
        "    def __init__(self, channels, num_heads, expansion_factor):\n",
        "        super(ResidualTransformerBlock, self).__init__()\n",
        "\n",
        "        self.norm1 = nn.LayerNorm(channels)\n",
        "        self.attn = MDTA(channels, num_heads)\n",
        "        self.norm2 = nn.LayerNorm(channels)\n",
        "        self.ffn = GDFN(channels, expansion_factor)\n",
        "\n",
        "    def forward(self, x):\n",
        "        attn_out = self.attn(self.norm1(x))\n",
        "        x = x + attn_out\n",
        "        ffn_out = self.ffn(self.norm2(x))\n",
        "        x = x + ffn_out\n",
        "        return x"
      ],
      "metadata": {
        "id": "Nuvz2JypyqT4"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}