{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyP+YtS9SU3+6ArraJbvFWYa",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/travislatchman/Single-Image-Deraining/blob/main/BasicRestormer.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### he original Restormer model is quite complex and contains many components. In this basic version, I've simplified the architecture by using fewer Transformer blocks and eliminating the downsampling and upsampling layers. This should make the model easier to train and understand, while still providing reasonable performance for single-image deraining tasks."
      ],
      "metadata": {
        "id": "NILU-aMvyJpS"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "soX4-J4Hx8Oe"
      },
      "outputs": [],
      "source": [
        "class BasicRestormer(nn.Module):\n",
        "    def __init__(self, num_blocks=4, num_heads=4, channels=48, expansion_factor=2):\n",
        "        super(BasicRestormer, self).__init__()\n",
        "\n",
        "        self.embed_conv = nn.Conv2d(3, channels, kernel_size=3, padding=1, bias=False)\n",
        "\n",
        "        self.transformer_blocks = nn.Sequential(*[TransformerBlock(\n",
        "            channels, num_heads, expansion_factor) for _ in range(num_blocks)])\n",
        "\n",
        "        self.output = nn.Conv2d(channels, 3, kernel_size=3, padding=1, bias=False)\n",
        "\n",
        "    def forward(self, x):\n",
        "        fo = self.embed_conv(x)\n",
        "        ft = self.transformer_blocks(fo)\n",
        "        out = self.output(ft) + x\n",
        "        return out"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### enhance the Restormer model with Residual Connections"
      ],
      "metadata": {
        "id": "FvjrUYZmyUQ0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class ResidualTransformerBlock(nn.Module):\n",
        "    def __init__(self, channels, num_heads, expansion_factor):\n",
        "        super(ResidualTransformerBlock, self).__init__()\n",
        "\n",
        "        self.norm1 = nn.LayerNorm(channels)\n",
        "        self.attn = MDTA(channels, num_heads)\n",
        "        self.norm2 = nn.LayerNorm(channels)\n",
        "        self.ffn = GDFN(channels, expansion_factor)\n",
        "\n",
        "    def forward(self, x):\n",
        "        attn_out = self.attn(self.norm1(x))\n",
        "        x = x + attn_out\n",
        "        ffn_out = self.ffn(self.norm2(x))\n",
        "        x = x + ffn_out\n",
        "        return x"
      ],
      "metadata": {
        "id": "Nuvz2JypyqT4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Add downsampling and upsampling layers: Implement a U-Net-like architecture by incorporating downsampling and upsampling layers between the Transformer blocks. This can help the model to capture hierarchical features at different scales, which could improve its performance on the deraining task."
      ],
      "metadata": {
        "id": "ZmBZKY59y0di"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Downsample(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels):\n",
        "        super(Downsample, self).__init__()\n",
        "        self.conv = nn.Conv2d(in_channels, out_channels, kernel_size=3, stride=2, padding=1, bias=False)\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.conv(x)\n",
        "\n",
        "\n",
        "class Upsample(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels):\n",
        "        super(Upsample, self).__init__()\n",
        "        self.conv = nn.Conv2d(in_channels, out_channels * 4, kernel_size=3, padding=1, bias=False)\n",
        "        self.pixel_shuffle = nn.PixelShuffle(2)\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.pixel_shuffle(self.conv(x))"
      ],
      "metadata": {
        "id": "gTfQuM7dy9VO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class UNetRestormer(nn.Module):\n",
        "    def __init__(self, num_blocks=4, num_heads=4, channels=48, expansion_factor=2):\n",
        "        super(UNetRestormer, self).__init__()\n",
        "\n",
        "        self.embed_conv = nn.Conv2d(3, channels, kernel_size=3, padding=1, bias=False)\n",
        "\n",
        "        # Encoder layers\n",
        "        self.enc_transformer_blocks = nn.Sequential(*[ResidualTransformerBlock(\n",
        "            channels, num_heads, expansion_factor) for _ in range(num_blocks)])\n",
        "\n",
        "        self.downsample = Downsample(channels, channels * 2)\n",
        "\n",
        "        # Bottleneck layers\n",
        "        self.bottleneck_transformer_blocks = nn.Sequential(*[ResidualTransformerBlock(\n",
        "            channels * 2, num_heads, expansion_factor) for _ in range(num_blocks)])\n",
        "\n",
        "        self.upsample = Upsample(channels * 2, channels)\n",
        "\n",
        "        # Decoder layers\n",
        "        self.dec_transformer_blocks = nn.Sequential(*[ResidualTransformerBlock(\n",
        "            channels, num_heads, expansion_factor) for _ in range(num_blocks)])\n",
        "\n",
        "        self.output = nn.Conv2d(channels, 3, kernel_size=3, padding=1, bias=False)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Encoder\n",
        "        fo = self.embed_conv(x)\n",
        "        enc_out = self.enc_transformer_blocks(fo)\n",
        "        enc_down_out = self.downsample(enc_out)\n",
        "\n",
        "        # Bottleneck\n",
        "        bottleneck_out = self.bottleneck_transformer_blocks(enc_down_out)\n",
        "\n",
        "        # Decoder\n",
        "        upsampled_out = self.upsample(bottleneck_out)\n",
        "        dec_in = torch.cat([upsampled_out, enc_out], dim=1)  # Skip connection\n",
        "        dec_out = self.dec_transformer_blocks(dec_in)\n",
        "\n",
        "        # Output\n",
        "        out = self.output(dec_out) + x\n",
        "        return out"
      ],
      "metadata": {
        "id": "mIzyFjmzzC2z"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}